Hello all, my name is Krishnaik and Welcome to my YouTube channel. So guys, yet another amazing video. In this particular video I will show you how you can go ahead and create your MCP servers completely from scratch. Along with that I will also talk about two important transport protocol that you can use along with this MCP server that is with respect to HDDIO and HTTP, we will create two different MCP servers and we will also create a client or application end which will be able to integrate with this particular MCP server. And here the library that we are going to specifically use is LangChain and Lang Graph. So please make sure that you watch this video till the end because right now MCP is in buzz. Many people do definitely ask in interviews and you definitely need to know how you can integrate MCP servers or build MCP server from scratch with the help of some popular frameworks like langdaf and LangChain. So yes, let's go ahead with the tutorial. Hello guys. So in this video we are going to discuss about how you can build your own MCP servers. Along with that you'll also be seeing that how you can integrate any kind of MCV servers that you built along with your app. So here is one basic diagram. Here you can see there are three main components. One is MCP Servers, MCP Client and App. Whenever I talk about MCP servers here you can have multiple tools. Just imagine that there is a other company, third party companies which are developing this kind of services. It can be simple, mathematical, you know, calculations. It can be third party, APIs, integrations, anything. It can be specifically written over here, here with respect to this MCP server. It provides you context tools and prompts to the client. And similarly you have something called as MCP Client here the client maintains one to one connection with the server inside the host app. And finally you also have an app. It can be a cloudy desktop or it can be any kind of app that you are specifically developing. So in this video what I am actually going to show you is that how we can go ahead and develop this entirely and how we can also build MCP server from basics and from scratch. Okay, so first of all what we are basically going to do is that we will be having this, this application. Let's say that this is the application that I am currently building, okay? Inside this application we are going to use LangChain or Lang graph. Okay? Application, we will be having some kind of chatbot application in short. Okay, now this chatbot application may have different, different LLM integrated in this. So Whenever a user provides any input. Okay, so let's say user provides any input. So based on this particular input, the LLM should be able to make a decision whether it has to make any kind of call from an MCP server. Okay? And let's say that this MCP server has some of the important tools. Let's say we have tools like addition, multiplication. I'm just showing this as an example. And let's say that we also go ahead and create one more tool here which is just like a weather call API. Okay? Weather Call API. Now here you will be able to see that this is my MCP server itself. And this MCP server is connected to this tools which are like add, multiplication, weather call API is anything as such. So let's say if I go ahead and ask a question, hey, what is the weather of New York or Bangalore? You know? So the LLM obviously will not be able to answer because obviously LLM do not have live information. So what this will do is that it will make a tool call and this time the tool call will be with the help of MCP protocol here internally there will be a client that will be developed which is called as MCP client. Okay? And then once this communication is made, then that specific, you know, API tools, whichever based on the input will be called and you finally get a response. Okay, so if I talk about like how this entire communication basically happens, first of all, when we get the input right, direct the call will go to the MCP server. The MCP server will give you all the necessary tools, along with what all information it has regarding that particular tool. Then the LLM will make a decision. Then the LLM takes this particular input and passes it to the MCP server to get the response. So this is a basic kind of communication that actually happens. And I have already covered in depth already in my MCP module itself, right in my previous videos. So this is how the basic communication basically happens right now here what we are going to focus on is that I will show you how you can go ahead and create your MCP server from scratch. Okay? Here we are going to use one of the most popular library which is called as LangChain. And in LangChain there is a library which is called as LangChain adapters, okay? So that we will be going to use. Second, I will show you how you can go ahead and create your MCP client. And whenever we talk about MCP protocol or whenever we talk about communication with the MCP servers, there are different, different transport protocol that we use, okay? Transport protocol that we use. Now, some of the transport protocol like there are some kind of arguments which actually helps you to communicate with any kind of tools itself. So one of the tool that we are going to use is something called as stdio and the other tool that we are basically going to use is related to HTTP protocol. Okay, so we'll try to understand what are the differences between them and we'll try to also use them again from coding point of view. I'll show you how this also works. Okay, we will be developing our MCP server. We'll also be developing our MCP client in this MCP server. When I talk with respect to the tools this tool, one of the tool, we will try to run it with the help of transport protocol that is HTD IO and the other one we will try to use HTTP. Okay, and we'll also talk about the differences, what exactly? This, both this transport mechanism, how does it vary? You know. So now let me quickly go ahead and let me open and this, we are going to completely start from scratch. So first of all, I am inside my drive. Okay, so this is the MCP demo LangChain. So here you can see I will open my cursor id. I hope everybody has the cursor ID now. Okay, now from this cursor id, what I am actually going to do is that I am going to go ahead and open this particular folder location as my project. Okay? So here I will go ahead and give this particular path and I will select the folder. Okay, now the first step, when you are specifically using cursor or whenever you work in any kind of projects, it is good that you try to create a environment. Right now before creating an environment, I need to initialize this particular workspace as a UV you with the help of the UV package. Okay? So if you know about uv, it is quite faster. You'll be able to probably do the development very, very much fast with respect to the package management of the entire project itself, right? Any Python project. So let's say that I'm going to go ahead and initialize this workspace with the help of UV package. So I'll write UV in it. So this is the first step. Now here you can see based on this, there are some files that has been already created. Okay? And if I talk with respect to all the specific files that we have created over here, one very important thing is that you have to go ahead and see which Python version this entire, you know, the basic package is basically created with. So here you can see Python version is 3.13. Here you have this Pyproject 2 ML. So right now the dependency is empty because we have not installed any kind of dependencies right now. Right? But we will go ahead and install it. Right? And this is the basic project information. Now to start with any project, I will go ahead and create my virtual environment. In order to create the virtual environment with the help of uv, it is very simple, simple. So I will go ahead and write UV vnv. Okay, now here it shows that, okay, my VNV environment has got created. Now any packages that I install, I have to install inside this. So first of all, I will go ahead and activate my environment. In order to activate, I will just go ahead and copy this command and paste it over here. Okay, so now we have activated my environment itself. Okay, now this is done. Now the next step is that we go ahead and install some of the packages. Okay, now we will see how to install the packages. But before that I will just go ahead and create my requirement TXT requirement.txt okay, now with respect to requirement TXT, I will just go ahead and write what all libraries I will be requiring. Okay, so two libraries that I specifically want to use. One is LangChain grok and then you also have something like LangChain adapters, right? So as I said, we're going to go ahead and use some of the libraries that are available with respect to this, that is LangChain adapters. And with the help of LangChain adapters, you will definitely be able to use this MCP properties even in LangChain. Okay, so here you can see, I'll write LangChain MCP adapter. Sorry, it is MCP adapters. Along with this I'm also going to use one library which is called as fast MCP Fast mcp. Okay, so here with respect to fast mcp, you can actually see this what exactly this is. Okay, so let me just go ahead and search for fast MCP again. So if I talk about fast MCP here you can see it is the fast Pythonic. It is written something like pythonic way to build MCP server and client. Okay, so we are going to specifically use this. This is a very, very easy way of creating MCP tools and all. So definitely I will show you step by step how you can basically use this fast MCP library and develop your entire MCP servers from scratch. Okay, step by step we'll go ahead and implement it. Now quickly here we are going to create three more important files. Okay, now what all files needs to be created based on this. That is what I'm going to discuss and understand based on the use cases, right? I have to. I've already told you that I'm going to use one MCP server which has this add multiplication and we'll use the transport as studio and we'll create another MCP server which will be communicating to this tool that is called as Weather Call API and it will use this HTTP tool, right? Transport mechanism. Okay? Transport mechanical mechanism basically means the communication between the client and the MCP server. How it is basically going to happen. Okay? And so what we are basically going to do is that over here I will just go ahead and write all my packages that is specifically required, okay? And along with this I will also go ahead and import mcp. Okay? So this MCP will actually help us to use the package fastmcp itself. Okay, now here is my requirement txt. The next step is that how do I go ahead and install all this particular libraries? It is very simple. I will go ahead and write UV add minus R requirement txt like how we used to write PIP install requirement txt. Similarly, we'll go ahead and do this. Okay, so now I'm going to go ahead and clear the screen and just to confirm whether all the installation has happened or not. So here you can basically go ahead and check out all those installation with respect to this. Okay? Till here everything looks good. Our installation has happened perfectly and we have already, you know, installed all the packages that is required. Okay, now let me just go ahead and create some important tools, right? With respect to the MCP server. So first tool that I'm actually going to create, it's nothing but Math server. Okay? So Math server py. So this is just like my MCP server. And here we are going to define some of the tools that we are basically going to use. Okay, so quickly in order to use this, as I said, I'm going to use Fast MCP. So I'll write from mcp.server.fast MCP. I'm going to go ahead and import Fast MCP. Okay? And once we do this, the next step is that we need to initialize this mcp. Right? So I'll go ahead and write MCP is equal to fast MCP. And I will give my tool name, which is nothing but math. Okay? So I'll give my tool name which is nothing but math. Okay, now inside this tool, sorry, inside the server, this is just a server name, okay? Not tool name because math is just a basic server name over here. Then the next Step is that I will just go ahead and write at the rate MCP dot tool. And this is how we go ahead and create our first tool which is present inside this MCP server. So create a definition, I'll write add. I'm just starting with a basic example so that, see, sky's the limit as we say, right? You want to go ahead and write create any kind of tool, but it is important that you understand from basic stuff, right? So then my second parameter will be is equal to int. And this I'm going to give return it in the form of integer. Here I'm going to probably provide some doc string. And based on this doc string, the LLM will be able to understand which tool to specifically call. So here I will write add two numbers, okay? And then we are going to go ahead and return A plus B. Okay? Then the next tool is nothing but MCP tool. And here we are going to go ahead and define, multiply a colon int comma b colon int. Again, you can go ahead and define any number of tools as you want. So this will return an int type. And here I'll just go ahead and write multiply, multiply two numbers. Okay? Some information that I'm specifically giving. And I'll go and write return a, return A multiplied by B. Okay? Now the thing is that, see, I am planning to create this MCP server with respect to this addition, multiplication or any kind of tool on the transport stdio. Now we need to understand what this stdio transport basically means, okay? And what you will be able to do from it. And it is important that we get a clear understanding about that because many people have seen that they try to write this particular code, but we fail to explain this, okay? What does MCP dot run? You know, so let's say that I want to run this particular file. How do I go, go ahead and run this? First of all, I'll go ahead and write the code so quickly I will write mcp.run so here what I'm actually going to do, I'll just say if underscore underscore name_/ double equal to__ main__ and here I will just go ahead and write MCP dot run. And we are going to run this entire application of MCP using the transportation transport double equal to stdio. Okay, now here we have used a transport called as stdio. Now we need to understand what this transport is. And for this I will just go ahead and put some basic Information so that you should be able to read it within the material itself. Okay, so here I will write two important comments. The transport is equal to stdio and here one more sentence. See, it tells the server to use standard input output to receive and respond to the tool functional calls. Now see what this is, right? When we say input output, right? The standard input output. The standard input output is like let's say if this is a server, if it is running this will specifically run in some kind of command prompt. Let's say in one of the scenario what we can do is that if I have a client and I want that client to interact with this particular server, then what we'll do if we have written this transport is equal to stdio, we will run this particular file directly in the command prompt and get the input and output there itself. Like let's say if I want to probably get given input, that input should go with respect to the command line itself. Hit any function and get the response out there. And the client should be able to read the information out directly from the STD out. That basically means from the command prompt itself, right? So this kind of thing is very helpful if you really want to test out things locally. You have your server executed in the locally itself and you really want to go ahead and test it with the client, right? So at that point of time you can use stdio. Okay, so this is the basic functionality with respect to this. So this is one of the server that we have basically created. The another server that I am really interested in creating is about. Let's say there may be a third party API call. You know that API call can be with respect to weather. It can be anything as such. But just to show it to you, I will quickly go ahead and create one weather PY file. Okay, now weather PY file. See now at the end of the day I'll also talk about like how do you probably take it to the production and what exactly goes into the production. Also I'll not show you directly by executing this in the cloud, but I'll give you a brief idea how things works over here, right? So here I will go ahead and write from mcp.server.fast mcp import fast mcp. Okay, and then I'm going to go ahead and write MCP is equal to fast MCP and this time this particular server name will be my weather. Okay, now here I'm going to go ahead and create my MCP tool. Okay, now in a real world scenario, if I talk about that this is my MCP Server and I want to probably take an input and give the weather of a specific location. That is the code that I'm going to write it over here. Okay? But for right now I'm just going and defining something. So I'll go ahead and write, hey, this is my get weather functionality and let's say this is my location, okay? This is my location, this is my str and this will basically return a str, okay? And then what I will do, I will go ahead and write my doc string, get the, get the, get the weather location. Okay? Weather location. Now this can be any code. This can be a code which, which will be interacting with some kind of third party API and getting the weather right. For right now I'll just return some constant value. So let's say here I'll write it's, it's always rainy, it's always raining and California. Let's say I'll just go ahead and write this message, okay? It may not be a true weather, but I just want to give you an idea. Let's say that this is the output of my API that I'm getting here. You can write any code with respect to interacting with some kind of APIs and then I will go ahead and write if. Underscore_ name_ underscore underscore underscore main underscore underscore right? So here my program execution will basically start. This should be double equal to. Okay, now what I will do, I will quickly write mcp.run and this time I'm going to use another transport. See, whenever I want something. See the before the one, one transport mechanism that we have specifically used is nothing but stdio, right? Stdio. I have told you the importance of. In this we are going to use streamable HTTP, right? HTTP. Now you need to understand what this exactly means. Okay, so guys, now let's understand what this transport streamable HTTP will do. Okay, now here, in order to make you understand what exactly the functionality is, right? So I'll just go ahead and open my terminal. Now inside my terminal, what I will do, I will just go ahead and run this, see python weather.py let's run this. Okay, now here you can see that this entire application, this entire server is running in this particular URL. Okay? When we use streamable HTTP transport, what it is going to do is that it is going to run as an API service itself. Okay? Similarly if I go ahead and run this math server right in stdio, it will not run like that. See here it will not run like that. Instead it will try to get. It will. It will not run in any kind of HTTP protocol, but instead it uses standard input and output. Okay, so if I just go ahead and execute this python math server.py here you can see that nothing is happening, right? So that basically means internally as the command prompt it is getting executed. Okay, but if I see in this particular use case, when we are using whether.PI with the help of transport is called as streamable HTTP, here you can see that it is working. It is running in the form of an API with this particular URL. So here, after this transport you can also go ahead and set up your URL and all. And with respect to that you can also set up the port. Okay, but right now we are not running this, we are running this as an HTTP, right? So by default you will be able to see it is taking my localhost and the default port is 8,000 thousand. Now the question rises. Chris. Fine, you, you told me the differences between streamable HTTP and obviously STD where my transport was HTT out, right? So here I have used stdio. Right? So you, you have told the differences between this. But how do we go ahead and integrate it from the client side? So here what I will do, I'll go ahead and write client py. So see, I have created two servers. One is the math server and one is the weather server. Now it's time that we go ahead and go ahead go ahead and write our client PY file. So let this things get running. Now I'm going to go ahead and focus on understanding that how do you go ahead and write the client py? At the end of the day, this client py should be able to interact with math server py and weather py. So for this I'll be using from langchen_mcp adapters.client. so we have to first of all go ahead and create a client. And this client should be, according to the documentation that is given from the lang graph, it should be a multi server MCP client. Okay, that basically means supports multi server itself. Then in lang graph, whenever I want to probably call any of this particular client, we need to create an agent. That agent will be responsible in integrating all these particular models. LLM models or tools Tools basically means all these MCP tools and all right, so for this we will be using pre built. So from lang graph.pre built. So first of all I will just go ahead and quickly add lang graph also because I require lang graph. Okay, so here I'LL open my command prompt, another command prompt and I'll write Hey UV add minus R requirement txt okay, so this is perfect. And then you'll be able to see that if I just go back to my client py now I will be able to import it. So from langarf.pre built create react agent so for creating an agent so that based on the input the agent, the LLM will be able to act an agent itself. And you know, in my previous videos I've all discussed about this, if you're following the series of videos that we have developed, right then from LangChain underscore grok import chat grok so I'm going to go ahead and use chat grok also and then from LangChain underscore OpenAI OpenAI will not going to use so from LangChain underscore core I'm also going to go ahead and use or let's say for right now I will just go ahead and use like this from dot ENV import load underscore env and then I'll go ahead and initialize this load underscore dot ENV and then I will also import async IO right now the next thing is that I definitely require my env file so quickly let me go ahead and create my env file. This is just for my LLM model, right? So I'll write grok API key since I'm going to use grok API key now I hope everybody, if you're following all the tutorials that I have created till now, you should know how to create a grok API key, right? So here is my groq API key. I'll go back to my client and inside this particular client I'll start going and writing my content, right? My code, sorry. Now what I'm going to do, I'll go ahead and write async definition main. Okay? And here we are basically going to go ahead and create our client. This client that we are going to create will be my multi server HTTP client, sorry, MCP client. And here I will give the client key value pairs, right? So the first client that I want to create so first server that I want to create, right? So this client will be able to interact with this MCP server. So it will be my math server. In the math server, let's say the command that I want to use in order to execute my math server will be nothing but Python because you can use Python or uv, it is up to you, okay, Python and then the next parameter that we Give is argument. Okay, let's see some a lot of suggestion that comes in this, right? So arguments. So inside the arguments I will give my another parameter and that parameter will be nothing but it will be my file name. So here I'm going to go ahead and write mathserver python. Please make sure to give the right location. So here, since this is my current working directory, I'm directly giving the name of the file. If it is inside any folder I have to give the entire relative path. Okay so once this is done, sorry, not relative path, absolute path. So here I'll go ahead and write the comment ensure correct absolute path. Okay, then my next parameter over here is nothing but my transport protocol. Like sorry, my transport metrics that we really want to give. So here based on the transport that we have used what transport we will be using it is nothing but stdio. Okay so here I will go ahead and write stdio. Okay so this actually completes all our parameter with respect to maths. Now similarly I will go ahead and add my another tool. So this is my maths tool over here. Okay, I'll go ahead and write it like this. Now coming to the next tool it is nothing but my weather tool. So if you see my weather tool it will be something like this whether localhost8000/mcp ensure server is running here. So if you see over here my server it is running where it is running in this localhost and when I do slash MCP that basically means it will be able to get all the MCP servers that it is running all sorry this particular weather where it is specifically running in this particular URL. Right? So here obviously my local host is there. But if you see/mcp this is where we will be able to find the entire MCP running. Okay so this will be my URL over here, right? So now till here it is really really good easy itself Here we have just created our multi server client. Now remember this cloud client is what will be interacting with this particular servers, right? So now I will go ahead and quickly write import OS and then I will go ahead and set up my environment. So OS environment it will be nothing but grok underscore API underscore key and here I will just write OS get env with my gro API underscore three okay then I'll go ahead and write my tools it will be await first of all in order to get the tools I can use client.get underscore tools. Okay now see this client is nothing but this client, right? And when we write dot get tools. I will be getting the information of both these tools like math and weather. Right? Then I will go ahead and initialize my model. My model is called a chat grock and I'm going to go ahead and use a model name which is Nothing but when q wq 32 billion parameter. Okay? Then I will go ahead and create my agent and this agent will be create react agent. And here I'm going to go ahead and write model comma tools. Right? So this is the two important parameter that we need to give in order to make the agent. Now I can use this agent and directly call invoke with respect to any messages that we specifically give. So let's say if I just go ahead and execute this math underscore response. So here you can see I'm just executing this. Just a second. So import OS. This is done. Okay, now math underscore response await agent.inquoke I'm giving the messages equal to role with user content. I've just written what is three multiplied by five multiplied by two. Okay, three plus five multiplied by two. And here I should be able to print my response. Print my response. So here in order to print my response, I will write hey, maths response colon. Okay, math response is equal to. I'll just go ahead and give this and then I'll write math underscore response. I will take the messages key. I will take the last message that is available out there and I will go ahead and read the content. Okay? Okay dot content will give the output of the maths response. Okay, now since this main function is async, so in order to run this, we are basically going to use async IO.rain okay? And here we are going to call the main function. Okay, so whenever we use async IO whenever we define any method that is async, we have to go ahead and run this with this particular library which we have imported it over here. Okay, so here we are just trying to get the match response. Okay, now let's go ahead and execute this. I will go ahead and open my command prompt. Now understand, very important thing, when I am calling this agent, right? It is invoking which tool based on this particular message, it will invoke this tool. And you know, in this tool the transport is stdio. That basically means this tool is going to run in the normal standard IO device, standard input or output device. That is nothing but command line. So. So that the input will directly go over there and get the output from there. Okay, so here in order to execute this, if I go ahead and write Python client py. Okay, now you should be able to see. Cancel this. You should be able to see what will be the output for this. What's three plus five multiplied by 12? Okay, so this is my input. Now you should be able to see what will be the output. Here's the step by step breakdown. Addition three plus five is equal to eight. Multiplication, eight multiplied by two is equal to 19. Match response is nothing but the result of three plus five multiplied by two is 96. So eight multiplied by 12 it is nothing but 96. This is absolutely perfectly fine. Okay, so here you can quickly see that how we are able to call our MCP server and that is nothing but our math server which is running in this stdio right now. The other thing is that if I also want to check the weather weather server, right? So for the weather server again I will go ahead and write like something like this. See, I'll give a question quickly and it will be the same thing. See weather response await agent.involved content. What is the weather in NYC or California? Right, California. Now this, it will take this particular message, but right now I have hard coded the output. It. It always. It always rains and it is always raining in California. Right? We have written like this. So my weather response should probably come the same thing. What we are getting directly from the weather py. Okay, so I will go ahead and run this once again and before running this I will also go ahead and print the output. Okay, so this is my weather response. Yeah, it is printed. So now if I just go ahead and execute this again. Python client py. First of all I should be getting my maths response. And the second thing is that I should be getting my weather response. Okay, so quickly, let's see this. And this is how you are basically communicating from one client to multiple servers itself, right? So it is taking some amount of time. Okay, See at some times, you know, sometime this kind of errors will come. You just need to go ahead and restart it. Okay, but now it will not. It will not. This kind of error will not come. Okay, so now you'll be able to see that it will do the execution. So here you can see the result of three plus five weather response. The tool indicator. It is always raining in California, but in reality California has a diverse climate. So LLM is also able to add some information which is good. But here now the tool is basically returning this. Okay, so that is the reason again it depends on what kind of API functionality you are implementing. It the best part is that this is running in a streamable HTTP. So like it's running in the form of in some URL. You can just see that. And we are integrating that in client py, right? And this is the URL that we are getting it with, slash mcp. Right? And all these things with the help of LangChain adapter, right? So I hope you are able to understand this particular example. Now what you can do is that you can close all the, all the, all the servers what you're running. But these are some, some servers that are independently running and you're integrating them in a single client. Okay. So these were two ways of calling. One is HD IO transport and streamable HTTP transfer. So here we have created a client. So in short, what all things we did. So we created a client and this client were able to communicate with two MCP servers. Okay. So this communication was basically happening. This MCP server, this MCP server, it is basically communicating with your transport equal to HD IO. And this MCP server you are able to communicate with HTTP protocol, transport protocol. And here, see, this entire thing is basically set up with MCP protocol itself. So we had that MCP server client, right? In this you had some tools like math, additional subtraction, whatever tool you want to create. And this was like a weather API, right? The main thing is that when you're running this tool, you are basically communicating with respect to the response from the STDIO itself. That basically means from the command prompt here we were using some kind of URL, right? So that is the reason we use HTTP. So I hope you understood this particular video. I hope you understood the coding mechanism that we specifically dead how we implemented each and every step. This was it from my side. I hope you like this particular video. I'll see you in the next video. Thank you. Take care.